---
name: Develop & Production
menu: Server Settings
route: /server-settings/develop-production
---

## Built React Files

리액트 빌드 결과물은 정적 파일로서 Load Balancer 웹서버 단에 복사하여 서비스를 할 수도 있습니다. 하지만 파일복사를 통한 배포의 경우, 배포버전관리나 rollback의 어려움이 있습니다. 도커 컨테이너를 통한 배포를 통해 이러한 어려움을 극복할 수 있습니다.

### Dockerfile 샘플

node 이미지를 통해 리액트 프로젝트를 빌드하고, nginx 이미지를 통해 빌드된 내역을 서빙토록 하여, 도커 이미지에는 빌드환경이 포함되지 않고, 최소한의 크기로 빌드가 됩니다.

```yaml
#
# 빌드 환경
#
FROM node:13 as builder

# 작업 디렉토리 지정 (없는 디렉토리라면 자동 생성이 됩니다.)
# cd (change directory) 역할까지 수행해줍니다.
WORKDIR /reactproject

# 전체 소스코드 복사
COPY . /reactproject

# 팩키지 설치 및 빌드
RUN yarn && yarn build

#
# 릴리즈 환경
#
FROM nginx:1.17-alpine

# 기존 nginx 설정을 대체합니다.
COPY conf/nginx.conf /etc/nginx/nginx.conf

# 빌드환경에서 빌드내역을 nginx 서빙경로로 복사합니다.
COPY --from=builder /reactproject/build /usr/share/nginx/html

# 웹서버이기에 http well known 포트인 80번으로 노출합니다.
EXPOSE 80

# nginx 웹서버를 Foreground 모드로 구동합니다.
CMD ["nginx", "-g", "daemon off;"]
```

### conf/nginx.conf 샘플

nginx 기본 이미지 상의 nginx.conf 설정파일에서 location 설정만 변경토록 합니다. 리액트 서빙에서는 어떤 URL 요청이 오더라도 단일 index.html 파일을 서빙토록 해야만 합니다. 요청받은 URL에 대한 라우팅 처리는 Client Side인 리액트 단에서 로직으로 처리를 하기 때문입니다.

```yaml
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections  1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';
    access_log /var/log/nginx/access.log  main;
    sendfile on;
    keepalive_timeout 65;

    server {
        listen 80;
        root /usr/share/nginx/html;

        # 변경된 부분
        index index.html;
        location / {
            try_files $uri $uri/ /index.html;
        }
    }
}
```

### Nginx Load Balancer에서의 Reverse Proxy 설정

지정 도메인 (server_name 설정)으로 유입된 요청을 proxy_pass에 지정된 웹서버로 전달하고 받은 응답을 그대로 클라이언트에게 응답합니다. proxy_pass 설정은 아이피:포트 형식으로 지정할 수 있으며, 네트워크 상의 다양한 웹서버로 요청을 전달할 수 있습니다. 그 대상은 단일 VM 상의 웹서비스일 수도 있으며, Docker Swarm 혹은 Kubernetes 상의 웹서비스일 수도 있습니다. 모두 웹서비스용 단일 Endpoint URL을 가집니다.

```yaml
server {
    listen 80;
    listen [::]:80;

    # 서비스 도메인
    server_name example.pusan.ac.kr;

    location / {
        proxy_buffering off;
        proxy_pass http://localhost:8081;
        proxy_redirect off;
    }
}
```

---

## Django API Server

### Dockerfile

아래 설정을 통해 Debian Buster 기반으로 빌드되며 gunicorn을 통해 웹서비스토록 합니다. 웹서비스에 따라 gunicorn 옵션 변경을 통해 최적화를 수행합니다.

```yaml
FROM python:3.8-slim-buster AS builder

# OS레벨에서 필요한 팩키지 설치
RUN apt-get update && \
    apt-get install -y gcc default-libmysqlclient-dev libjpeg-dev

# 작업 디렉토리 지정 (없는 디렉토리라면 자동 생성이 됩니다.)
# cd (change directory) 역할까지 수행해줍니다.
WORKDIR /djangoproject

# 팩키지 리스트 파일 복사 및 파이썬 팩키지 설치
COPY requirements/ /djangoproject/requirements/
COPY requirements.txt /djangoproject
RUN pip install -r requirements.txt

# 장고 프로젝트 소스코드 복사
COPY . /djangoproject

# 표준출력/표준에러에 대해 버퍼링을 수행하지 않도록 합니다.
# 환경변수 값만 설정을 하면 설정된 값은 어떤 값이 되든 상관이 없습니다.
ENV PYTHONUNBUFFERED=1

# 웹서버이기에 http well known 포트인 80번으로 노출합니다.
EXPOSE 80

# gunicorn을 통해 장고 애플리케이션을 구동합니다. Gunicorn 팩키지 설치는
# 위의 requirements.txt 상에 명시되어있어야만 설치가 먼저 이뤄집니다.
# 모든 컨테이너는 로그 출력을 표준출력으로 처리하기에 access 로그출력을 표준출력으로 지정합니다.
# Memory Leak이 발생하더라도 서버 자동 재시작을 통해 서버가 안정적으로 서비스될 수 있도록 합니다.
# 아래 예제에서는 요청 1000±50번 범위 내에서 자동 재시작토록 되어있습니다.
CMD gunicorn \
    --access-logfile - \
    backend.wsgi:application \
    --bind 0.0.0.0:80 \
    --max-requests 1000 \
    --max-requests-jitter 50
```

### Nginx Load Balancer 에서의 Reverse Proxy 설정

지정 도메인 (server_name 설정)으로 유입된 요청을 proxy_pass에 지정된 웹서버로 전달할 때, 추가로 헤더를 설정하여 전달하고, 받은 응답을 그대로 클라이언트에게 응답합니다. Load Balancer가 요청을 중계하기에 REMOTE_ADDR 헤더가 클라이언트 IP가 아닌 Load Balancer의 IP가 됩니다. 그렇기에 추가 헤더를 통해 클라이언트 정보를 전달토록 해야만, 장고 단에서 클라이언트의 IP를 파악할 수 있게 됩니다.

```yaml
server {
    listen 80;
    listen [::]:80;

    # 서비스 도메인
    server_name api.example.pusan.ac.kr;

    location / {
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;       # 포워딩 아이피
        proxy_set_header Host $http_host;
        proxy_set_header X-Forwarded-Proto $scheme;                        # 프로토콜
        proxy_set_header X-NginX-Proxy true;
        proxy_buffering off;
        proxy_pass http://localhost:8081;
        client_max_body_size 200M;
        proxy_redirect off;
    }
}
```

---

## File Server

장고 API Server는 단일 인스턴스로 구동되는 것이 아니라, 서비스 상황에 따라 멀티 인스턴스로 서비스될 수 있으며, 그 인스턴스들은 여러 VM에 걸쳐서 존재할 수 있습니다. 그렇기에 멀티 인스턴스에 의해 Read/Write할 수 있으며, 동시에 웹서버의 기능도 가진 File Server가 필요해지게 됩니다. 파일 Read/Write를 위한 인터페이스로 NFS, FTP, SFTP 등이 가능합니다만, 이 중에 보안에 유리하고 유연하며 신뢰성있는 인터페이스로 SFTP를 채용토록 합니다.

1. SFTP 지원을 위해 SSH 서버 설치가 필요합니다.
   - SSH 서버 운영이 어렵다면 NFS 서버를 설정하고, 관련 설정을 Django Container 운영 시에 환경변수를 통한 설정이 필요합니다.
   - NFS은 파일 시스템 인터페이스이기 때문에 장고에서 기본 지원하고 있으며, SFTP의 경우 django-storages 라이브러리를 통해 지원하고 있습니다.
2. HTTP 파일 서빙을 위해 nginx 서버 설치가 필요합니다.
3. OS는 윈도우/맥/리눅스 모두 가능합니다만, Ubuntu 리눅스 서버가 최신 팩키지가 빠르게 지원되기 때문에, 보다 쾌적하게 서버를 운영할 수 있습니다.
4. 안정적인 File Server 서비스를 위해 2~3중화 백업이 필요할 수도 있습니다. 이를 위해 별도의 정적 파일 저장소 솔루션이 필요합니다.

---

## Database Server

Container와 무관하게 조직에서 데이터베이스를 설치/운영하는 방식으로 데이터베이스를 셋업하고, 장고 API 서버에서 접근할 수 있도록 네트워크 설정을 맞춰줍니다.

1. 장고에서는 RDBMS를 장고 기본에서 지원하고 있습니다. 1개 이상의 RDBMS를 하나의 장고 프로젝트와 연동할 수 있습니다. 다수의 DB를 지원할려면 장고 프로젝트에서 DB Router를 구현하여야만 합니다.

---

## Cache Server

Container와 무관하게 조직에서 데이터베이스를 설치/운영하는 방식으로 캐시 서버를 셋업하고, 장고 API 서버에서 접근할 수 있도록 네트워크 설정을 맞춰줍니다. 대표적인 캐시 서버로는 Memcached와 Redis가 있습니다. 프로젝트 성격에 따라 선택합니다.

1. Memcached : 메모리 기반 단순 Key/Value 캐시서버. 일반적인 목적의 캐시에 적합합니다.
2. Redis : Memcached보다 기능이 많은 캐시서버이자 NoSQL 서버. Memcached에 비해 메모리를 많이 먹지만, 다양한 데이터 타입과 API를 지원합니다.
